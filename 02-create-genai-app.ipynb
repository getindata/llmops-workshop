{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playground #2 - building Gen AI application"
   ],
   "metadata": {
    "id": "YI4O30zXVsuM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dependencies installation\n",
    "!pip install langchain langchain-community langchain-openai tiktoken langfuse lancedb langgraph docling langchain-docling gradio python-dotenv"
   ],
   "metadata": {
    "id": "WxfPyVTcVpWE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "# Set environment variables from secrets\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_HOST\"] = userdata.get(\"LANGFUSE_HOST\")"
   ],
   "metadata": {
    "id": "GUJ3JsHgWJzV"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Knowledge base"
   ],
   "metadata": {
    "id": "C6KxJWRDW6Fl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "from docling_core.transforms.chunker.hierarchical_chunker import HierarchicalChunker\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions\n",
    "\n",
    "\n",
    "# Document to be ingested\n",
    "SOURCE = \"https://web.seducoahuila.gob.mx/biblioweb/upload/the_wonderful_wizard_of_oz.pdf\"\n",
    "\n",
    "\n",
    "# Configure converter\n",
    "docling_converter = DocumentConverter(\n",
    "    allowed_formats=[InputFormat.PDF],\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=PdfPipelineOptions(\n",
    "                do_ocr=False\n",
    "            ),\n",
    "            ocr_options=EasyOcrOptions(\n",
    "                force_full_page_ocr=False,\n",
    "                lang=[\"en\"]\n",
    "            )\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Configure loader\n",
    "loader = DoclingLoader(\n",
    "    file_path=SOURCE,\n",
    "    export_type=ExportType.DOC_CHUNKS,\n",
    "    chunker=HierarchicalChunker()\n",
    ")\n",
    "\n",
    "documents = loader.load_and_split()\n",
    "\n"
   ],
   "metadata": {
    "id": "eMI-Yit3WfPl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# play around exploring the content od documents collection\n",
    "\n",
    "print(f\"Number of text chunks: {len(documents)}\")\n",
    "print(f\"First chunk: {documents[0].page_content}\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")\n"
   ],
   "metadata": {
    "id": "5spncvT7Xef1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create knowledge base for lookups (LanceDB)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import LanceDB\n",
    "import lancedb\n",
    "\n",
    "\n",
    "def safe_get_page_no(data):\n",
    "  \"\"\"Helper function that extracts page number from metadata \"\"\"\n",
    "  dl_meta = data.get('dl_meta', {})\n",
    "  doc_items = dl_meta.get('doc_items', [])\n",
    "  if not doc_items: return None\n",
    "  prov = doc_items[0].get('prov', [])\n",
    "  return prov[0].get('page_no') if prov else None\n",
    "\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "vector_store = LanceDB.from_texts(\n",
    "    [doc.page_content.replace(\"\\t\", \" \") for doc in documents],\n",
    "    embedding_function,\n",
    "    metadatas=[{\"page_no\": safe_get_page_no(doc.metadata)} for doc in documents],\n",
    "    table_name=\"knowledge_base\",\n",
    "    connection=lancedb.connect(\"temp/wizard_of_oz\")\n",
    ")"
   ],
   "metadata": {
    "id": "gHRq2YjA5x7E"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# play around with vector_store\n",
    "\n",
    "vector_store.similarity_search(\"How many witches where in the book?\", k=5)\n"
   ],
   "metadata": {
    "id": "O9BByOXj7dkG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vector_store.similarity_search_with_relevance_scores(\"Who was the tinman?\", k=4)"
   ],
   "metadata": {
    "id": "xvHgU77E7sj3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Orchestrating the application flow"
   ],
   "metadata": {
    "id": "6cChHlkp89ir"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "NUMBER_OF_SNIPPETS_TO_RETRIEVE = 5\n",
    "\n",
    "# Define graph state\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    snippets: list\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Node #1 - retrieval\n",
    "def retrieve_snippets(state: RAGState):\n",
    "  retriever = vector_store.as_retriever(search_kwargs={\"k\": NUMBER_OF_SNIPPETS_TO_RETRIEVE})\n",
    "  snippets = retriever.get_relevant_documents(state[\"question\"])\n",
    "  return {\"snippets\": snippets}\n",
    "\n",
    "\n",
    "# Node #2 - generation\n",
    "def generate_answer(state: RAGState):\n",
    "  context = \"\\n\\n\".join(doc.page_content for doc in state[\"snippets\"])\n",
    "  prompt = f\"Using the context below, answer the question.\\n\\nQuestion: {state['question']}\\nContext: {context}\\nAnswer:\"\n",
    "  answer = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o-mini\").invoke(prompt).content\n",
    "  return {\"answer\": answer}\n",
    "\n",
    "# Build the state graph with sequential nodes\n",
    "graph_builder = StateGraph(RAGState).add_sequence([retrieve_snippets, generate_answer])\n",
    "graph_builder.add_edge(START, \"retrieve_snippets\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "graph = graph_builder.compile()\n"
   ],
   "metadata": {
    "id": "E9MNk1Pj7_26"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Try running the RAG generation\n",
    "response = graph.invoke({'question': \"What shoes did Dorothy wear?\"})\n",
    "response['answer']"
   ],
   "metadata": {
    "id": "mi0kwAbt9rlK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Explore the response object\n",
    "response"
   ],
   "metadata": {
    "id": "wAgPNhkx-vtw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Adding a UI"
   ],
   "metadata": {
    "id": "ADC2fjSJ_XAN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_oz_question(question: str):\n",
    "    response = graph.invoke({'question': question})\n",
    "    return response['answer']\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=answer_oz_question,\n",
    "    inputs=gr.Textbox(label=\"Question\"),\n",
    "    outputs=gr.TextArea(label=\"Answer\", interactive=False)\n",
    ")\n",
    "demo.launch(share=True)"
   ],
   "metadata": {
    "id": "Gm44pb3T_VoA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* exercise 1: Try to make number of snippets used for answer generation configurable via the UI\n",
    "* exercise 2*: Try to add the information which page was used for the answer generation a part of the answer"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
