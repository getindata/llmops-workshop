{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __include.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# MODEL = \"qwen2.5:14b\"\n",
    "# MODEL = \"gemma3:12b\"\n",
    "# MODEL = \"granite3.2:2b\"\n",
    "# MODEL=\"smollm2:1.7b\"\n",
    "# MODEL=\"smollm2:360m\"\n",
    "# MODEL=\"smollm2:135m\"\n",
    "MODEL = \"phi4:14b\"\n",
    "\n",
    "lm = dspy.LM(f\"ollama/{MODEL}\", cache=False)\n",
    "dspy.settings.configure(lm=lm, track_usage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sms_classifier import SMSClassifier\n",
    "\n",
    "sms_classifier = SMSClassifier(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_classifier(\n",
    "    sms_text=\"\"\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = langfuse.get_dataset(\"sms_phishing_test\")\n",
    "from dspy import Example\n",
    "\n",
    "test_ds = []\n",
    "for item in dataset.items:\n",
    "    test_ds.append(\n",
    "        Example(sms_text=item.input, category=item.expected_output).with_inputs(\n",
    "            \"sms_text\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_helpers import validate_answer\n",
    "from langfuse_extensions import EvaluateWithLangfuse\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "session_id = f\"Run-{MODEL}-{int(datetime.now().timestamp())}\"\n",
    "# print(session)\n",
    "\n",
    "\n",
    "evaluator = EvaluateWithLangfuse(\n",
    "    devset=test_ds,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    session_id=session_id,\n",
    "    lm=lm,\n",
    "    provide_traceback=True,\n",
    ")\n",
    "\n",
    "dspy.configure(callbacks=[evaluator])\n",
    "evaluator(program=sms_classifier, metric=validate_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.cybersecurity.evaluation_helpers import calculate_metrics, fetch_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_qwen25_1_5 = fetch_traces(run_id=\"Run-qwen2.5:1.5b-1743285619\")\n",
    "metrics_qwen25_1_5 = calculate_metrics(traces_qwen25_1_5, classes)\n",
    "metrics_qwen25_1_5[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_qwen25_3 = fetch_traces(run_id=\"Run-qwen2.5:3b-1743285575\")\n",
    "metrics_qwen25_3 = calculate_metrics(traces_qwen25_3, classes)\n",
    "metrics_qwen25_3[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_qwen25_0_5 = fetch_traces(run_id=\"Run-qwen2.5:0.5b-1743285668\")\n",
    "metrics_qwen25_0_5 = calculate_metrics(traces_qwen25_0_5, classes)\n",
    "metrics_qwen25_0_5[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_gemma_1 = fetch_traces(run_id=\"Run-gemma3:1b-1743286064\")\n",
    "metrics_gemma_1 = calculate_metrics(traces_gemma_1, classes)\n",
    "metrics_gemma_1[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_gemma_4 = fetch_traces(run_id=\"Run-gemma3:4b-1743286278\")\n",
    "metrics_gemma_4 = calculate_metrics(traces_gemma_4, classes)\n",
    "metrics_gemma_4[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_granite32_2 = fetch_traces(run_id=\"Run-granite3.2:2b-1743286838\")\n",
    "metrics_granite32_2 = calculate_metrics(traces_granite32_2, classes)\n",
    "metrics_granite32_2[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_gemma_12 = fetch_traces(run_id=\"Run-gemma3:12b-1743287333\")\n",
    "metrics_gemma_12 = calculate_metrics(traces_gemma_12, classes)\n",
    "metrics_gemma_12[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_qwen25_14 = fetch_traces(run_id=\"Run-qwen2.5:14b-1743287701\")\n",
    "metrics_qwen25_14 = calculate_metrics(traces_qwen25_14, classes)\n",
    "metrics_qwen25_14[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_smollm2_1_7 = fetch_traces(run_id=\"Run-smollm2:1.7b-1743288291\")\n",
    "metrics_smollm2_1_7 = calculate_metrics(traces_smollm2_1_7, classes)\n",
    "metrics_smollm2_1_7[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_smollm2_360 = fetch_traces(run_id=\"Run-smollm2:360m-1743288463\")\n",
    "metrics_smollm2_360 = calculate_metrics(traces_smollm2_360, classes)\n",
    "metrics_smollm2_360[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ham\", \"spam\", \"smishing\"]\n",
    "# specify the run_id of the model to evaluate\n",
    "traces_phi4_14 = fetch_traces(run_id=\"Run-phi4:14b-1743289137\")\n",
    "metrics_phi4_14 = calculate_metrics(traces_phi4_14, classes)\n",
    "metrics_phi4_14[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_baseline = dict()\n",
    "metrics_baseline[\"smollm2:360m\"] = metrics_smollm2_360[\"macro\"]\n",
    "metrics_baseline[\"smollm2:1.7b\"] = metrics_smollm2_1_7[\"macro\"]\n",
    "metrics_baseline[\"qwen2.5:0.5b\"] = metrics_qwen25_0_5[\"macro\"]\n",
    "metrics_baseline[\"qwen2.5:1.5b\"] = metrics_qwen25_1_5[\"macro\"]\n",
    "# metrics_baseline[\"qwen2.5:3b\"] = metrics_qwen25_3[\"macro\"]\n",
    "metrics_baseline[\"gemma3:1b\"] = metrics_gemma_1[\"macro\"]\n",
    "metrics_baseline[\"gemma3:4b\"] = metrics_gemma_4[\"macro\"]\n",
    "metrics_baseline[\"granite3.2:2b\"] = metrics_granite32_2[\"macro\"]\n",
    "metrics_baseline[\"gemma3:12b\"] = metrics_gemma_12[\"macro\"]\n",
    "metrics_baseline[\"qwen2.5:14b\"] = metrics_qwen25_14[\"macro\"]\n",
    "metrics_baseline[\"phi4:14b\"] = metrics_phi4_14[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_helpers import plot_metrics\n",
    "\n",
    "plot_metrics(\n",
    "    metrics_baseline,\n",
    "    [\"Precision\", \"Recall\", \"F1\"],\n",
    "    \"Scores by model before optimization\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
