{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playground #1 - setup"
   ],
   "metadata": {
    "id": "YI4O30zXVsuM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. On the left hand side (key icon) add a secret OPENAI_API_KEY with the value provided by us.\n",
    "2. Allow notebook access with toggle on the left.\n",
    "2. TODO decide if we want to create new langfuse project or reuse existing one."
   ],
   "metadata": {
    "id": "bIvDPdt-Vx8-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dependencies installation\n",
    "# libraries installation\n",
    "!pip install langchain langchain-community langchain-openai tiktoken langfuse"
   ],
   "metadata": {
    "id": "WxfPyVTcVpWE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "# Set environment variables from secrets\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_HOST\"] = userdata.get(\"LANGFUSE_HOST\")"
   ],
   "metadata": {
    "id": "GUJ3JsHgWJzV"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test embeddings generation"
   ],
   "metadata": {
    "id": "C6KxJWRDW6Fl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "embedding_result = embeddings.embed_query(test_text)\n",
    "assert embedding_result is not None\n",
    "print(f\"Embedding API access works!\")"
   ],
   "metadata": {
    "id": "eMI-Yit3WfPl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# See the generated embedding\n",
    "print(embedding_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test LLM connectivity"
   ],
   "metadata": {
    "id": "WeDorTL4XZKq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "temperature = 0.5\n",
    "model = \"gpt-4o-mini\"\n",
    "chat = ChatOpenAI(temperature=temperature, model_name=model)\n",
    "response = chat.invoke(\"Tell me a joke about GenAI\")\n",
    "assert response is not None\n",
    "print(f\"LLM access works! output: \\n{response.content}\")"
   ],
   "metadata": {
    "id": "MTXAO3ZAW_zW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Explore the content of a response object"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test langfuse connectivity"
   ],
   "metadata": {
    "id": "Vojnf4FyX_8k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    "assert langfuse.auth_check()\n",
    "print(f\"Langfuse access works!\")"
   ],
   "metadata": {
    "id": "IJeG_YpfYCLE"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
